{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess BursSR dataset for RAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:12:41.821468Z",
     "start_time": "2020-10-01T16:12:41.635000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\default.desktop-frpmn5g\\anaconda3\\lib\\site-packages (4.5.4.60)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\default.desktop-frpmn5g\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in c:\\users\\default.desktop-frpmn5g\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: torch==1.10.1 in c:\\users\\default.desktop-frpmn5g\\anaconda3\\lib\\site-packages (from torchvision) (1.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\default.desktop-frpmn5g\\anaconda3\\lib\\site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\default.desktop-frpmn5g\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\default.desktop-frpmn5g\\anaconda3\\lib\\site-packages (from torch==1.10.1->torchvision) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: exifread in c:\\users\\default.desktop-frpmn5g\\anaconda3\\lib\\site-packages (2.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%pip install opencv-python\n",
    "%pip install torchvision\n",
    "%pip install exifread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:12:41.994463Z",
     "start_time": "2020-10-01T16:12:41.822701Z"
    }
   },
   "outputs": [],
   "source": [
    "# import utils and basic libraries\n",
    "# from RAMS.utils.preprocessing import load_dataset,select_T_images,register_dataset,augment_dataset\n",
    "\n",
    "from burst_preprocess_utils import load_dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:12:42.003213Z",
     "start_time": "2020-10-01T16:12:41.995586Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------------\n",
    "# Settings\n",
    "#-------------\n",
    "T = 8                                # number of temporal dimension\n",
    "n_augment = 7                        # number of temporal permutations to augment the dataset\n",
    "dataset_dir = 'burstsr_dataset'          # input dir (train val and test splitted)\n",
    "dataset_output_dir = 'burstsr_preprocessed'       # output dir\n",
    "threshold_clean = 0.85               # percentage of clear pixel\n",
    "train_full = False                   # train without a validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"loading\"></a>\n",
    "# 1.0 Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:12:49.002476Z",
     "start_time": "2020-10-01T16:12:42.004060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ccc96a33aa4bb0b94422f2f8254232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scenes: 2000 | Train y shape: (2000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Default.DESKTOP-FRPMN5G\\Documents\\Master\\UC\\project\\burst_preprocess_utils.py:58: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return X,X_masks,np.array(y),np.array(y_masks)\n",
      "c:\\Users\\Default.DESKTOP-FRPMN5G\\Documents\\Master\\UC\\project\\burst_preprocess_utils.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return X,X_masks,np.array(y),np.array(y_masks)\n"
     ]
    }
   ],
   "source": [
    "# train loading\n",
    "X_train, X_train_masks, y_train, y_train_masks = load_dataset(base_dir=dataset_dir, \n",
    "                                                              part=\"train\",\n",
    "                                                              colored_image=False)\n",
    "print(f\"Train scenes: {len(X_train)} | Train y shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:12:51.960208Z",
     "start_time": "2020-10-01T16:12:49.003244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96db2b60731f41ebbb6ab6b8c3facbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/882 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val RED scenes: 882 | Val RED y shape: (882,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Default.DESKTOP-FRPMN5G\\Documents\\Master\\UC\\project\\burst_preprocess_utils.py:58: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return X,X_masks,np.array(y),np.array(y_masks)\n",
      "c:\\Users\\Default.DESKTOP-FRPMN5G\\Documents\\Master\\UC\\project\\burst_preprocess_utils.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return X,X_masks,np.array(y),np.array(y_masks)\n"
     ]
    }
   ],
   "source": [
    "# validation loading\n",
    "X_val, X_val_masks, y_val, y_val_masks = load_dataset(base_dir=dataset_dir,\n",
    "                                                      part=\"val\",\n",
    "                                                      colored_image=False)\n",
    "\n",
    "print(f\"Val RED scenes: {len(X_val)} | Val RED y shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:12:53.861099Z",
     "start_time": "2020-10-01T16:12:51.961150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e61b275f7924488bc76272ee236a863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c7d46a531444b5967fe72e4d627184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RED scenes: 146\n",
      "Test NIR scenes: 144\n"
     ]
    }
   ],
   "source": [
    "# test loading\n",
    "#burst sr bevat geen test set\n",
    "# X_RED_test, X_RED_test_masks = load_dataset(base_dir=dataset_dir,part=\"test\",band=\"RED\")\n",
    "# X_NIR_test, X_NIR_test_masks = load_dataset(base_dir=dataset_dir,part=\"test\",band=\"NIR\")\n",
    "\n",
    "# print(f\"Test RED scenes: {len(X_RED_test)}\")\n",
    "# print(f\"Test NIR scenes: {len(X_NIR_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualize\"></a>\n",
    "# 3.0 Visualize the Pre-Processed Datataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:21:13.294008Z",
     "start_time": "2020-10-01T16:21:13.286858Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------------\n",
    "# Settings\n",
    "#-------------\n",
    "index = 200\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:21:13.741233Z",
     "start_time": "2020-10-01T16:21:13.294890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, T, figsize=(20,5))\n",
    "\n",
    "for i in range(T):\n",
    "    ax[0,i].imshow(X_train[index][...,i], cmap = 'gray')\n",
    "    ax[0,i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "# 4.0 Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:31:11.107260Z",
     "start_time": "2020-10-01T16:31:11.092658Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(dataset_output_dir):\n",
    "    os.mkdir(dataset_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:31:33.137574Z",
     "start_time": "2020-10-01T16:31:12.508857Z"
    }
   },
   "outputs": [],
   "source": [
    "# save training\n",
    "np.save(os.path.join(dataset_output_dir, 'X_RED_train.npy'), X_RED_train)\n",
    "np.save(os.path.join(dataset_output_dir, 'X_NIR_train.npy'), X_NIR_train)\n",
    "\n",
    "np.save(os.path.join(dataset_output_dir, 'y_RED_train.npy'), y_RED_train)\n",
    "np.save(os.path.join(dataset_output_dir, 'y_NIR_train.npy'), y_NIR_train)\n",
    "\n",
    "np.save(os.path.join(dataset_output_dir, 'y_RED_train_masks.npy'), y_RED_train_masks)\n",
    "np.save(os.path.join(dataset_output_dir, 'y_NIR_train_masks.npy'), y_NIR_train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:31:34.766852Z",
     "start_time": "2020-10-01T16:31:34.528430Z"
    }
   },
   "outputs": [],
   "source": [
    "# save validation\n",
    "if not train_full:\n",
    "    np.save(os.path.join(dataset_output_dir, 'X_RED_val.npy'), X_RED_val)\n",
    "    np.save(os.path.join(dataset_output_dir, 'X_NIR_val.npy'), X_NIR_val)\n",
    "\n",
    "    np.save(os.path.join(dataset_output_dir, 'y_RED_val.npy'), y_RED_val)\n",
    "    np.save(os.path.join(dataset_output_dir, 'y_NIR_val.npy'), y_NIR_val)\n",
    "\n",
    "    np.save(os.path.join(dataset_output_dir, 'y_RED_val_masks.npy'), y_RED_val_masks)\n",
    "    np.save(os.path.join(dataset_output_dir, 'y_NIR_val_masks.npy'), y_NIR_val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T16:31:36.249034Z",
     "start_time": "2020-10-01T16:31:36.167724Z"
    }
   },
   "outputs": [],
   "source": [
    "# save test\n",
    "np.save(os.path.join(dataset_output_dir, 'X_RED_test.npy'), X_RED_test)\n",
    "np.save(os.path.join(dataset_output_dir, 'X_NIR_test.npy'), X_NIR_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ccc597fa2502b1ad4253efe9be6e1fc8a92ff2520684e2cc7fc85e3c4166c01a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
